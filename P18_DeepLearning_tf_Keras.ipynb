{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "honey-venezuela",
   "metadata": {},
   "source": [
    "# Deep Learning using tf.keras\n",
    "\n",
    "**Deep learning** is a subset of machine learning, which is essentially a neural network with three or more layers. <br>\n",
    "\n",
    "While a neural network with a single layer can still make approximate predictions, additional hidden layers can help to optimize and refine for accuracy.<br>\n",
    "\n",
    "Deep learning drives many artificial intelligence (AI) applications and services that improve automation, performing analytical and physical tasks without human intervention (digital assistants, voice-enabled TV remotes, credit card fraud detection, ...) as well as emerging technologies (such as self-driving cars).<br>\n",
    "\n",
    "Deep neural networks consist of multiple layers of interconnected nodes, each building upon the previous layer to refine and optimize the prediction or categorization. <br>\n",
    "\n",
    "This progression of computations through the network is called **forward propagation**. <br>\n",
    "The input and output layers of a deep neural network are called visible layers. The **input layer** is where the deep learning model ingests the data for processing, and the **output layer** is where the final prediction or classification is made.\n",
    "\n",
    "Another process called **backpropagation** uses algorithms, like gradient descent, to calculate errors in predictions and then adjusts the weights and biases of the function by moving backwards through the layers in an effort to train the model. <br>\n",
    "\n",
    "Together, forward propagation and backpropagation allow a neural network to make predictions and correct for any errors accordingly. Over time, the algorithm becomes gradually more accurate.<br>\n",
    "\n",
    "The above describes the simplest type of deep neural network in the simplest terms. However, deep learning algorithms can be very complex, and there are different types of neural networks to address specific problems or datasets. <br>\n",
    "For example:\n",
    "\n",
    "- **Convolutional neural networks** (CNNs), used primarily in computer vision and image classification applications, can detect features and patterns within an image, enabling tasks, like object detection or recognition. In 2015, a CNN bested a human in an object recognition challenge for the first time.<br>\n",
    "- **Recurrent neural network** (RNNs) typically used in natural language and speech recognition applications as it leverages sequential or times series data.\n",
    "\n",
    "## Keras and TensorFlow\n",
    "\n",
    "**Keras** is an open-source deep learning library (project started in 2015) written in Python.<br>\n",
    "\n",
    "Created by the Google Brain team, **TensorFlow** is an open source library (project also started in 2015) for numerical computation and large-scale machine learning. <br>\n",
    "TensorFlow bundles together a slew of machine learning and deep learning models and algorithms and makes them useful by way of a common metaphor. <br>\n",
    "It uses Python to provide a convenient front-end API for building applications with the framework, while executing those applications in high-performance C++.<br>\n",
    "\n",
    "During the period of 2015-2019, developing deep learning models using `TensorFlow` (but also `Theano`, or `PyTorch`) was cumbersome, requiring tens or even hundreds of lines of code to achieve the simplest tasks. <br>\n",
    "The focus of these libraries was on flexibility, and speed, not ease of use.<br>\n",
    "\n",
    "`Keras` is popular because the API is clean and simple, allowing standard deep learning models to be defined, fit, and evaluated in just a few lines of code.\n",
    "\n",
    "`Keras` gives the possibility to use several popular deep learning mathematical libraries as the backend (to perform the computation), such as TensorFlow, Theano, or CNTK. This allowed the power of these libraries to be harnessed (e.g. GPUs) with a very clean and simple interface.<br>\n",
    "\n",
    "In 2019, Google released a new version of their TensorFlow deep learning library (**TensorFlow 2**) that integrated the Keras API directly and promoted this interface as the default or standard interface for deep learning development on the platform.<br>\n",
    "\n",
    "This integration is commonly referred to as the **tf.keras** interface or API.\n",
    "\n",
    "Given that TensorFlow is now the de facto standard backend for the Keras open source project, the integration means that a single library can now be used instead of two separate ones. <br>\n",
    "\n",
    "**Note**: you can install tensorflow using the traditionnal commands (`pip install tensorflow` or `conda install tensorflow`) and check it's version via: `tensorflow.__version__`\n",
    "\n",
    "This notebook will give you an overview of how to define a deep learning model using the **tf.keras** API.\n",
    "\n",
    "### The Keras Model Life-Cycle\n",
    "\n",
    "A **Keras** model has a life-cycle, similar to other models, composed of 5 steps:\n",
    "\n",
    "1. **Define the model**: defining the model requires that you first select the type of model that you need and then choose the architecture or network topology.<br> From an API perspective, this involves defining the **layers** of the model, configuring each layer with a **number of nodes** and **activation function**, and connecting the layers together into a cohesive model.<br> Models can be defined either with the **Sequential API** or the **Functional API**.<br>\n",
    "2. **Compile the model**: compiling the model requires that you first select a **loss** function that you want to optimize, such as `mean squared error` or `cross-entropy`.<br>It also requires that you select an algorithm to perform the **optimization procedure**, typically `stochastic gradient descent`, or a modern variation, such as `Adam`. <br>It may also require that you select any **performance metrics** to keep track of during the model training process.\n",
    "3. **Fit the model**: fitting the model requires that you first select the training configuration, such as the number of **epochs** (loops through the training dataset) and the **batch size** (number of samples in an epoch used to estimate model error).<br> Training applies the chosen optimization algorithm to minimize the chosen **loss** function and updates the model using the backpropagation of error algorithm.<br> Fitting the model is the slow part of the whole process and can take seconds to hours to days, depending on the complexity of the model, the hardware youâ€™re using, and the size of the training dataset.\n",
    "4. **Evaluate the model**: evaluating the model requires that you first choose a holdout dataset used to evaluate the model. <br>This should be data not used in the training process so that we can get an unbiased estimate of the performance of the model when making predictions on new data.<br>\n",
    "5. **Make predictions**: making a prediction is the final step (and goal) in the life-cycle. <br>It requires you have new data for which a prediction (a class label probability, a numerical value, ...) is required.<br>You may want to save the model and later load it to make predictions. <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-plaintiff",
   "metadata": {},
   "source": [
    "### The Sequential Model API \n",
    "\n",
    "The **sequential model API** is the simplest API.<br>\n",
    "\n",
    "It is referred to as \"sequential\" because it involves defining a **Sequential** class and adding layers to the model one by one in a linear manner, from input to output.<br>\n",
    "\n",
    "The example below defines a Sequential MLP model used for a classification problem. It accepts 4 inputs, has 2 hidden layers with 10 nodes and 8 nodes and then an output layer with 3 nodes (1 per class).<br>\n",
    "\n",
    "The input layer is created implicitly: it's size is defined by the **input_shape** argument on the first hidden layer. <br>\n",
    "That means in the following example, the model expects the input for one sample to be a vector of 4 numbers.\n",
    "\n",
    "The sequential API is easy to use: you keep calling **model.add()** until you have added all of your layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e614da",
   "metadata": {},
   "source": [
    "`\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(4,)))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-custom",
   "metadata": {},
   "source": [
    "### The Functional Model API \n",
    "\n",
    "The **Functional API** is more complex but is also more flexible.\n",
    "\n",
    "It involves explicitly connecting the output of one layer to the input of another layer. <br>\n",
    "\n",
    "Each connection is specified.<br>\n",
    "\n",
    "First, an input layer must be defined via the **Input** class, and the shape of an input sample is specified.<br>\n",
    "\n",
    "We must retain a reference to the input layer when defining the model:\n",
    "\n",
    "`l_in = Input(shape=(4,))`\n",
    "\n",
    "Next, a fully connected layer can be connected to the input by calling the layer and passing the input layer. This will return a reference to the output connection in this new layer:\n",
    "\n",
    "`l_hidden1 = Dense(10)(l_in)`\n",
    "\n",
    "We can then connect this to another hidden layer in the same manner:\n",
    "\n",
    "`l_hidden2 = Dense(8)(l_hidden1)`\n",
    "\n",
    "We can then connect this to an output layer:\n",
    "\n",
    "`l_out = Dense(1)(l_hidden1)`\n",
    "\n",
    "\n",
    "Once connected, we define a **Model** object and specify the input and output layers: \n",
    "\n",
    "`model = Model(inputs=l_in, outputs=l_out)`\n",
    "\n",
    "As such, it allows for more complicated model designs, such as models that may have multiple input paths (separate vectors) and models that have multiple output paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9bc2ac",
   "metadata": {},
   "source": [
    "`\n",
    "l_in = Input(shape=(n_features,))\n",
    "l_hidden1 = Dense(10,activation='relu', kernel_initializer='he_normal')(l_in)\n",
    "l_hidden2 = Dense(8,activation='relu', kernel_initializer='he_normal')(l_hidden1)\n",
    "l_out = Dense(3, activation='softmax')(l_hidden2)\n",
    "model = Model(inputs=l_in, outputs=l_out)\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-appearance",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron Models\n",
    "\n",
    "A **Multilayer Perceptron model**, or **MLP** for short, is a standard fully connected neural network model.<br>\n",
    "\n",
    "It is comprised of layers of nodes where each node is connected to all outputs from the previous layer and the output of each node is connected to all inputs for nodes in the next layer.<br>\n",
    "\n",
    "An MLP is created by with one or more `Dense` layers. <br>\n",
    "\n",
    "This model is appropriate for tabular data (data as it looks in a table or spreadsheet) with one column for each variable and one row for each observation. <br>\n",
    "\n",
    "There are three predictive modeling problems you may want to explore with an MLP:\n",
    "1. **`binary classification`**: \n",
    "1 or 2 or 3 hidden layer could be used (1 is enough usually).\n",
    "In this situation, it is a good practice to use **relu** activation with a **he_normal** weight initialization for the hidden layer(s).<br> \n",
    "The output layer will be composed of a single node.\n",
    "The output layer could use the **sigmoid** activation function. <br>\n",
    "The model can be optimized using the **adam** version of stochastic gradient descent and it could seeks to minimize the **cross-entropy** loss.<br>\n",
    "\n",
    "2. **`multiclass classification`**:\n",
    "1 or 2 or 3 hidden layer could be used (1 is enough usually).<br>\n",
    "In this situation also, it is a good practice to use **relu** activation with a **he_normal** weight initialization for the hidden layer(s).<br> \n",
    "The output layer will be composed of one node for each class and it will use the **softmax** activation function.<br>\n",
    "Given that it is a multiclass classification, the loss function `sparse_categorical_crossentropy`, could be used (it is appropriate for integer encoded class labels: 0 for one class, 1 for the next class, etc.).\n",
    "\n",
    "3. **`regression`**:\n",
    "1 or 2 or 3 hidden layer could be used (1 is enough usually).<br>\n",
    "In this situation also, it is a good practice to use **relu** activation with a **he_normal** weight initialization for the hidden layer(s).<br> \n",
    "A regression problem usually involves predicting a single numerical value. As such, the output layer has a single node and uses the default or **linear** activation function (no activation function).<br> \n",
    "The **mean squared error** (**mse**) loss can be used to minimized when fitting the model (being a regression, not a classification, we cannot calculate classification accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-postcard",
   "metadata": {},
   "source": [
    "### How many layers, how many nodes\n",
    "\n",
    "Every neural network is composed (at the maximum) of three types of layers: **input**, **hidden**, and **output**.<br>\n",
    "\n",
    "Creating the NN architecture therefore means coming up with values for the number of layers of each type and the number of nodes in each of these layers.<br>\n",
    "\n",
    "#### The Input Layer\n",
    "\n",
    "Every NN has exactly one **input layer**.<br>\n",
    "\n",
    "With respect to the number of neurons comprising this layer, this parameter is completely and uniquely determined once you know the shape of your training data: the number of neurons comprising that layer is equal to the number of features in your data. <br>\n",
    "\n",
    "Some NN configurations add one additional node for a **bias** term.\n",
    "\n",
    "#### The Output Layer\n",
    "\n",
    "Like the Input layer, every NN has exactly one **output layer**. <br> \n",
    "\n",
    "The size of the output layer is completely determined by the chosen model configuration.<br>\n",
    "\n",
    "Is the NN used for classification or regression ? <br>\n",
    "\n",
    "If the NN is a regressor, then the output layer has a single node.<br>\n",
    "\n",
    "If the NN is a classifier, then it also has a single node unless the activation `softmax` function is used in which case the output layer has one node per class label in your model.\n",
    "\n",
    "#### The Hidden Layers\n",
    "\n",
    "\n",
    "How many hidden layers? <br>\n",
    "\n",
    "Well if your data is linearly separable then you don't need any hidden layers at all (you don't even need an NN to resolve your data either, but it will still do the job).<br>\n",
    "\n",
    "Beyond that, it is difficult to determine, in advance, how many hidden layers are needed.<br>\n",
    "Nevertheless there is a consensus: adding additional hidden layers decrease the performance of the model. <br>\n",
    "\n",
    "One hidden layer is sufficient for the large majority of problems.<br>\n",
    "\n",
    "What about the size of the hidden layer(s)?<br>\n",
    "\n",
    "There are some empirically-derived rules-of-thumb, of these, the most commonly relied on is 'the optimal size of the hidden layer is usually between the size of the input and size of the output layers'. <br>\n",
    "One could probably get decent performance bychoosing a number of hidden layers equals one and a number of neurons in that layer computed as the mean of the neurons in the input and output layers.<br>\n",
    "\n",
    "Problems that require two hidden layers are rarely encountered. However, neural networks with two hidden layers can represent functions with any kind of shape.<br>\n",
    "\n",
    "There is no way to select automatically the number of layers and neurons in each layer, but there are networks that can build automatically their topology, like **EANN** (Evolutionary Artificial Neural Networks, which use Genetic Algorithms to evolved the topology).<br>\n",
    "\n",
    "If we except this last kind of NN, the best strategy to find the proper number of hidden layers is an empirical one: split your data into training, cross validation, and test sets, and train neural networks with 1, 2, and 3 hidden layers, then see which one has the lowest cross validation error to choose an architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-motorcycle",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "\n",
    "An **activation function** in a neural network defines how the weighted sum of the input is transformed into an output from a node or nodes in a layer of the network.<br>\n",
    "\n",
    "The choice of activation function has a large impact on the capability and performance of the neural network, and <u>different activation functions may be used in different parts of the model</u>.<br>\n",
    "\n",
    "Technically, the activation function is used within or after the internal processing of each node in the network, although networks are designed to use the <u>same activation function for all nodes in a layer</u>.<br>\n",
    "\n",
    "<u>All hidden layers typically use the same activation function</u>. <br>\n",
    "\n",
    "The output layer will typically use a different activation function from the hidden layers and is dependent upon the type of prediction required by the model.<br>\n",
    "\n",
    "Activation functions are also typically differentiable, meaning the first-order derivative can be calculated for a given input value. This is required given that neural networks are typically trained using the backpropagation of error algorithm that requires the derivative of prediction error in order to update the weights of the model.<br>\n",
    "\n",
    "There are many different types of activation functions used in neural networks, although perhaps only a small number of functions used in practice for hidden and output layers.<br>\n",
    "\n",
    "Typically, <u>a differentiable nonlinear activation function is used in the hidden layers</u> of a neural network. This allows the model to learn more complex functions than a network trained using a linear activation function.<br>\n",
    "\n",
    "#### Activation function for hidden layers\n",
    "\n",
    "There are perhaps three activation functions you may want to consider for use in hidden layers; they are:\n",
    "\n",
    "1. Rectified Linear Activation (ReLU)\n",
    "2. Logistic (Sigmoid)\n",
    "3. Hyperbolic Tangent (Tanh)\n",
    "\n",
    "##### ReLU \n",
    "\n",
    "**ReLU** activation function, is perhaps the most common function used for hidden layers.\n",
    "\n",
    "It is common because it is both simple to implement and effective at overcoming the limitations of other previously popular activation functions, such as `Sigmoid` and `Tanh`. Specifically, it is less susceptible to vanishing gradients that prevent deep models from being trained.\n",
    "\n",
    "The ReLU function is calculated as follows: if the input value is negative, then a value 0.0 is returned, otherwise, the value is returned.\n",
    "\n",
    "When using the ReLU function for hidden layers, it is a good practice to use a **He Normal** or **He Uniform** weight initialization and <u>scale input data to the range 0-1</u> (normalize) prior to training.<br>\n",
    "\n",
    "##### Sigmoid\n",
    "\n",
    "The **sigmoid** activation function is also called the logistic function. It is the same function used in the logistic regression classification algorithm.<br>\n",
    "\n",
    "The function takes any real value as input and outputs values in the range 0 to 1. The larger the input (more positive), the closer the output value will be to 1.0, whereas the smaller the input (more negative), the closer the output will be to 0.0.<br>\n",
    "\n",
    "The sigmoid activation function is calculated as follows: 1.0 / (1.0 + e^-x)<br>\n",
    "\n",
    "When using the Sigmoid function for hidden layers, it is a good practice to use a **Xavier Normal** or **Xavier Uniform** weight initialization (also referred to Glorot initialization) and <u>scale input data to the range 0-1</u> prior to training.\n",
    "\n",
    "##### Tanh \n",
    "\n",
    "The **Tanh** (hyperbolic tangent) activation function is very similar to the sigmoid activation function.<br>\n",
    "\n",
    "The function takes any real value as input and outputs values in the range -1 to 1. The larger the input (more positive), the closer the output value will be to 1.0, whereas the smaller the input (more negative), the closer the output will be to -1.0.<br>\n",
    "\n",
    "The Tanh activation function is calculated as follows: (e^x â€“ e^-x) / (e^x + e^-x)<br>\n",
    "\n",
    "When using the Tanh function for hidden layers, it is a good practice to use a **Xavier Normal** or **Xavier Uniform** weight initialization and <u>scale input data to the range -1 - +1</u> prior to training.<br>\n",
    "\n",
    "Both the `sigmoid` and `Tanh` functions can make the model more susceptible to problems during training, via the so-called vanishing gradients problem.<br>\n",
    "\n",
    "Modern neural network models with common architectures, such as MLP and CNN, will make use of the ReLU activation function, or extensions.<br>\n",
    "\n",
    "Recurrent networks still commonly use Tanh or sigmoid activation functions, or even both.<br> \n",
    "\n",
    "#### Activation for Output Layers\n",
    "\n",
    "The most commonly used activation functions for use in the output layer are:\n",
    "\n",
    "1. Linear\n",
    "2. Logistic (Sigmoid)\n",
    "3. Softmax\n",
    "\n",
    "##### Linear Output Activation Function\n",
    "\n",
    "The **linear activation** function (also called **identity**) does not change the weighted sum of the input in any way and instead returns the value directly.<br>\n",
    "\n",
    "Target values used to train a model with a linear activation function in the output layer are typically scaled prior to modeling using normalization or standardization transforms.<br>\n",
    "\n",
    "If your problem is a regression problem, you should use a linear activation function.<br>\n",
    "\n",
    "\n",
    "##### Sigmoid Output Activation Function\n",
    "\n",
    "Target labels used to train a model with a **sigmoid** activation function in the output layer will have the values 0 or 1.<br>\n",
    "\n",
    "If your problem is a classification problem with two mutually exclusive classes (binary classification), then your output layer will have one node and a `sigmoid` activation function should be used.<br>\n",
    "\n",
    "If there are two or more mutually inclusive classes (multilabel classification), then your output layer will have one node for each class and a `sigmoid` activation function should be used.\n",
    "\n",
    "##### Softmax Output Activation Function\n",
    "\n",
    "The **softmax** function outputs a vector of values that sum to 1.0 and that can be interpreted as probabilities of class membership.<br>\n",
    "\n",
    "Target labels used to train a model with the `softmax` activation function in the output layer will be vectors with 1 for the target class and 0 for all other classes.<br>\n",
    "\n",
    "If your problem is a classification problem with more than two mutually exclusive classes (multiclass classification), then your output layer will have one node per class and a softmax activation should be used. <br"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-patrick",
   "metadata": {},
   "source": [
    "### Which Optimizer, error function and metrics should I use?\n",
    "\n",
    "#### Optimizer\n",
    "\n",
    "Choosing a good optimizer for your machine learning project can be overwhelming. Popular deep learning libraries such as `PyTorch` or `TensorFLow` offer a broad selection of different optimizers â€” each with its own strengths and weaknesses.<br>\n",
    "\n",
    "The problem with choosing an optimizer is that there is no single optimizer to rule them all.<br>\n",
    "\n",
    "Almost all popular optimizers in deep learning are based on **gradient descent**. This means that they repeatedly estimate the slope of a given loss function and move the parameters in the opposite direction (hence climbing down towards a supposed global minimum). <br>\n",
    "The most simple example for such an optimizer is probably **stochastic gradient descent** (or **SGD**) which exists since the 1950s.<br> \n",
    "In the 2010s the use of `adaptive gradient methods` such as **AdaGrad**, **Adam** or **RMSProp** has become increasingly popular. <br>\n",
    "Recent trends in deep learning bring rise to new variants of SGD like **LARS**, **LAMB** or **Momentum**. <br>\n",
    "\n",
    "Some characteristics of your dataset will play to the strengths of certain optimizers:\n",
    "- Certain optimizers perform well on data with sparse features (AdaGrad, RMSProp, Adam).\n",
    "- Others may perform better when the model is applied to previously unseen data (SGD).\n",
    "- Some optimizers work very well with large batch sizes (LARS).\n",
    "- Others will converge to sharp minima with poor generalization (AdaGrad).\n",
    "\n",
    "As a rule of thumb: if you have the resources to find a good learning rate schedule **momentum** is a solid choice. If you are in need of quick results without extensive hypertuning, tend towards adaptive gradient methods like **Adam**.<br>\n",
    "\n",
    "#### Error/Loss function\n",
    "\n",
    "As part of the optimization algorithm, the error for the current state of the model must be estimated repeatedly. This requires the choice of an **error function**, conventionally called a **loss function,** that can be used to estimate the loss of the model so that the weights can be updated to reduce the loss on the next evaluation.<br>\n",
    "The loss function to use depend on the kind of problem you want to model, here are the most popular ones:\n",
    "1. Regression Loss Functions\n",
    "- Mean Squared Error Loss\n",
    "- Mean Squared Logarithmic Error Loss\n",
    "- Mean Absolute Error Loss\n",
    "2. Binary Classification Loss Functions\n",
    "- Binary Cross-Entropy (when the target values are in the set {0, 1})\n",
    "- Hinge Loss (when the target values are in the set {-1, 1})\n",
    "- Squared Hinge Loss (when the target values are in the set {-1, 1})\n",
    "3. Multi-Class Classification Loss Functions\n",
    "- Multi-Class Cross-Entropy Loss (the target variable must be one hot encoded: this can be achieved using the **to_categorical()** Keras function)\n",
    "- Sparse Multiclass Cross-Entropy Loss (does not require one hot encoding of the target variable)\n",
    "- Kullback Leibler Divergence Loss (the target variable must be one hot encoded)\n",
    "\n",
    "#### Metrics\n",
    "\n",
    "A **metric** is a function that is used to judge the performance of your model.<br>\n",
    "You may use any loss function as a metric.<br>\n",
    "\n",
    "Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model.<br>\n",
    "\n",
    "With Keras, the **compile()** method takes a metrics argument (a list of metrics).<br>\n",
    "\n",
    "Metric values are displayed during **fit()** and logged to the History object returned by **fit()**. <br>\n",
    "\n",
    "They are also returned by **model.evaluate()**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "refined-honor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "(100, 4) (50, 4) (100,) (50,)\n",
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 497us/step - loss: 1.7172 - accuracy: 0.3100\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 1.5897 - accuracy: 0.3100\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 838us/step - loss: 1.4704 - accuracy: 0.3100\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 501us/step - loss: 1.3634 - accuracy: 0.3100\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 1.2749 - accuracy: 0.3100\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 781us/step - loss: 1.1986 - accuracy: 0.3100\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 997us/step - loss: 1.1398 - accuracy: 0.3100\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 633us/step - loss: 1.0909 - accuracy: 0.3100\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0414 - accuracy: 0.3100\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 628us/step - loss: 1.0071 - accuracy: 0.3100\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.9826 - accuracy: 0.3300\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.9609 - accuracy: 0.4100\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 633us/step - loss: 0.9425 - accuracy: 0.5900\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 655us/step - loss: 0.9299 - accuracy: 0.6100\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 676us/step - loss: 0.9201 - accuracy: 0.6800\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 673us/step - loss: 0.9122 - accuracy: 0.6900\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 731us/step - loss: 0.9059 - accuracy: 0.6700\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 628us/step - loss: 0.8964 - accuracy: 0.6900\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 600us/step - loss: 0.8863 - accuracy: 0.6900\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 793us/step - loss: 0.8765 - accuracy: 0.6900\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 583us/step - loss: 0.8666 - accuracy: 0.7100\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.8573 - accuracy: 0.7200\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 875us/step - loss: 0.8487 - accuracy: 0.7600\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 996us/step - loss: 0.8395 - accuracy: 0.7800\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 643us/step - loss: 0.8329 - accuracy: 0.7900\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8253 - accuracy: 0.7900\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 688us/step - loss: 0.8174 - accuracy: 0.7900\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.8100 - accuracy: 0.7900\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8030 - accuracy: 0.8000\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 526us/step - loss: 0.7950 - accuracy: 0.8000\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 743us/step - loss: 0.7876 - accuracy: 0.8100\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 438us/step - loss: 0.7804 - accuracy: 0.8200\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 639us/step - loss: 0.7738 - accuracy: 0.7900\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.7664 - accuracy: 0.7600\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7602 - accuracy: 0.7700\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.7542 - accuracy: 0.7600\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7475 - accuracy: 0.7700\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.7408 - accuracy: 0.7700\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 576us/step - loss: 0.7341 - accuracy: 0.7700\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.8000\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 534us/step - loss: 0.7216 - accuracy: 0.7800\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 761us/step - loss: 0.7156 - accuracy: 0.7800\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 745us/step - loss: 0.7104 - accuracy: 0.7800\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 781us/step - loss: 0.7040 - accuracy: 0.7800\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.8200\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.6913 - accuracy: 0.8200\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 774us/step - loss: 0.6853 - accuracy: 0.8300\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 937us/step - loss: 0.6797 - accuracy: 0.8400\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 914us/step - loss: 0.6744 - accuracy: 0.8300\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 834us/step - loss: 0.6688 - accuracy: 0.8400\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 813us/step - loss: 0.6634 - accuracy: 0.8400\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 575us/step - loss: 0.6586 - accuracy: 0.8400\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 978us/step - loss: 0.6544 - accuracy: 0.8000\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.6499 - accuracy: 0.7700\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.6454 - accuracy: 0.7600\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 652us/step - loss: 0.6400 - accuracy: 0.7700\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6344 - accuracy: 0.7900\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 323us/step - loss: 0.6288 - accuracy: 0.8200\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 467us/step - loss: 0.6238 - accuracy: 0.8400\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 614us/step - loss: 0.6189 - accuracy: 0.8600\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 383us/step - loss: 0.6142 - accuracy: 0.8700\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 527us/step - loss: 0.6091 - accuracy: 0.8900\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.6047 - accuracy: 0.8800\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.8800\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.5956 - accuracy: 0.9000\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 243us/step - loss: 0.5911 - accuracy: 0.9300\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 516us/step - loss: 0.5871 - accuracy: 0.9200\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 521us/step - loss: 0.5831 - accuracy: 0.9200\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.5785 - accuracy: 0.9200\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.9200\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.5707 - accuracy: 0.9200\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.5668 - accuracy: 0.9300\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5627 - accuracy: 0.9400\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 429us/step - loss: 0.5589 - accuracy: 0.9400\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 506us/step - loss: 0.5553 - accuracy: 0.9300\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 507us/step - loss: 0.5513 - accuracy: 0.9400\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 619us/step - loss: 0.5476 - accuracy: 0.9400\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.5441 - accuracy: 0.9400\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 661us/step - loss: 0.5404 - accuracy: 0.9400\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.5369 - accuracy: 0.9500\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.5335 - accuracy: 0.9400\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 495us/step - loss: 0.5303 - accuracy: 0.9400\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 430us/step - loss: 0.5270 - accuracy: 0.9300\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 980us/step - loss: 0.5236 - accuracy: 0.9300\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.5203 - accuracy: 0.9300\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.5173 - accuracy: 0.9200\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 592us/step - loss: 0.5141 - accuracy: 0.9200\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.5102 - accuracy: 0.9500\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.5074 - accuracy: 0.9300\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 527us/step - loss: 0.5061 - accuracy: 0.9300\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.9100\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.5032 - accuracy: 0.8900\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 554us/step - loss: 0.4991 - accuracy: 0.9300\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4944 - accuracy: 0.9300\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4911 - accuracy: 0.9500\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4878 - accuracy: 0.9500\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.4856 - accuracy: 0.9500\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.4826 - accuracy: 0.9500\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.4804 - accuracy: 0.9300\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 322us/step - loss: 0.4783 - accuracy: 0.9400\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.4742 - accuracy: 0.9500\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.4713 - accuracy: 0.9500\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4705 - accuracy: 0.9400\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.4687 - accuracy: 0.9300\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4658 - accuracy: 0.9400\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4625 - accuracy: 0.9400\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.4601 - accuracy: 0.9500\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 374us/step - loss: 0.4574 - accuracy: 0.9500\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4553 - accuracy: 0.9500\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.4532 - accuracy: 0.9500\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4506 - accuracy: 0.9500\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 805us/step - loss: 0.4477 - accuracy: 0.9600\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.4458 - accuracy: 0.9700\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4431 - accuracy: 0.9800\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.4410 - accuracy: 0.9700\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 502us/step - loss: 0.4405 - accuracy: 0.9600\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.4389 - accuracy: 0.9400\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.4361 - accuracy: 0.9500\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4324 - accuracy: 0.9600\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 808us/step - loss: 0.4312 - accuracy: 0.9800\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.4300 - accuracy: 0.9500\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.4276 - accuracy: 0.9500\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.4247 - accuracy: 0.9700\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 804us/step - loss: 0.4232 - accuracy: 0.9800\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4210 - accuracy: 0.9800\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.4194 - accuracy: 0.9700\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.4171 - accuracy: 0.9800\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 722us/step - loss: 0.4159 - accuracy: 0.9800\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.4152 - accuracy: 0.9600\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4130 - accuracy: 0.9500\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.4112 - accuracy: 0.9500\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4089 - accuracy: 0.9700\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4071 - accuracy: 0.9800\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4048 - accuracy: 0.9700\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 540us/step - loss: 0.4031 - accuracy: 0.9700\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 324us/step - loss: 0.4028 - accuracy: 0.9600\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4005 - accuracy: 0.9600\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 495us/step - loss: 0.3980 - accuracy: 0.9700\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.3961 - accuracy: 0.9800\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3944 - accuracy: 0.9900\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.3927 - accuracy: 0.9900\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.3913 - accuracy: 0.9800\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3896 - accuracy: 0.9800\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 705us/step - loss: 0.3881 - accuracy: 0.9800\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.3864 - accuracy: 0.9900\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 496us/step - loss: 0.3854 - accuracy: 0.9700\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 532us/step - loss: 0.3843 - accuracy: 0.9700\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.3827 - accuracy: 0.9700\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 515us/step - loss: 0.3811 - accuracy: 0.9700\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 444us/step - loss: 0.3792 - accuracy: 0.9900\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 835us/step - loss: 0.3772 - accuracy: 0.9900\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.3759 - accuracy: 0.9800\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 506us/step - loss: 0.3747 - accuracy: 0.9800\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.3739 - accuracy: 0.9600\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3730 - accuracy: 0.9500\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 897us/step - loss: 0.3728 - accuracy: 0.9500\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.3713 - accuracy: 0.9500\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.3699 - accuracy: 0.9500\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3686 - accuracy: 0.9500\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 498us/step - loss: 0.3662 - accuracy: 0.9700\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 491us/step - loss: 0.3636 - accuracy: 0.9800\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.3627 - accuracy: 0.9900\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3608 - accuracy: 0.9800\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.9800\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.3583 - accuracy: 0.9800\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3571 - accuracy: 0.9800\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 382us/step - loss: 0.3561 - accuracy: 0.9800\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 580us/step - loss: 0.3543 - accuracy: 0.9800\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 610us/step - loss: 0.3532 - accuracy: 0.9800\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 427us/step - loss: 0.3521 - accuracy: 0.9800\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 531us/step - loss: 0.3508 - accuracy: 0.9800\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.3492 - accuracy: 0.9800\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3466 - accuracy: 0.9900\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 636us/step - loss: 0.3461 - accuracy: 0.9700\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.3453 - accuracy: 0.9700\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3441 - accuracy: 0.9700\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3439 - accuracy: 0.9600\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 613us/step - loss: 0.3424 - accuracy: 0.9600\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.3409 - accuracy: 0.9600\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3397 - accuracy: 0.9700\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 538us/step - loss: 0.3385 - accuracy: 0.9600\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.3373 - accuracy: 0.9700\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3352 - accuracy: 0.9700\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3335 - accuracy: 0.9700\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 646us/step - loss: 0.3320 - accuracy: 0.9700\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 954us/step - loss: 0.3304 - accuracy: 0.9800\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.3291 - accuracy: 0.9800\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 801us/step - loss: 0.3278 - accuracy: 0.9900\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 481us/step - loss: 0.3270 - accuracy: 0.9800\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 507us/step - loss: 0.3275 - accuracy: 0.9800\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 966us/step - loss: 0.3246 - accuracy: 0.9800\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.9800\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3215 - accuracy: 0.9800\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3205 - accuracy: 0.9800\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.96 - 0s 748us/step - loss: 0.3193 - accuracy: 0.9800\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.3182 - accuracy: 0.9800\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3175 - accuracy: 0.9700\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 560us/step - loss: 0.3165 - accuracy: 0.9700\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 899us/step - loss: 0.3153 - accuracy: 0.9700\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 506us/step - loss: 0.3144 - accuracy: 0.9700\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3128 - accuracy: 0.9700\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 996us/step - loss: 0.3117 - accuracy: 0.9800\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.3115 - accuracy: 0.9900\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 612us/step - loss: 0.3102 - accuracy: 0.9800\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3089 - accuracy: 0.9800\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.3070 - accuracy: 0.9900\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 579us/step - loss: 0.3071 - accuracy: 0.9800\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.3049 - accuracy: 0.9700\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.3041 - accuracy: 0.9700\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3025 - accuracy: 0.9800\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3018 - accuracy: 0.9800\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 393us/step - loss: 0.3006 - accuracy: 0.9700\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.3007 - accuracy: 0.9700\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3011 - accuracy: 0.9700\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.3010 - accuracy: 0.9700\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 622us/step - loss: 0.2992 - accuracy: 0.9700\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2959 - accuracy: 0.9700\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 319us/step - loss: 0.2933 - accuracy: 0.9900\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 755us/step - loss: 0.2939 - accuracy: 0.9800\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.2946 - accuracy: 0.9800\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2958 - accuracy: 0.9800\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2961 - accuracy: 0.9800\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 970us/step - loss: 0.2943 - accuracy: 0.9800\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 496us/step - loss: 0.2916 - accuracy: 0.9800\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2892 - accuracy: 0.9800\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2871 - accuracy: 0.9900\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 504us/step - loss: 0.2867 - accuracy: 0.9700\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 574us/step - loss: 0.2876 - accuracy: 0.9700\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 247us/step - loss: 0.2860 - accuracy: 0.9700\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 248us/step - loss: 0.2840 - accuracy: 0.9700\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2828 - accuracy: 0.9700\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 855us/step - loss: 0.2816 - accuracy: 0.9700\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2804 - accuracy: 0.9700\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2797 - accuracy: 0.9700\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 788us/step - loss: 0.2790 - accuracy: 0.9700\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.2780 - accuracy: 0.9700\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.2769 - accuracy: 0.9700\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 248us/step - loss: 0.2761 - accuracy: 0.9700\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 517us/step - loss: 0.2751 - accuracy: 0.9700\n",
      "Epoch 240/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 748us/step - loss: 0.2745 - accuracy: 0.9700\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2738 - accuracy: 0.9700\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 635us/step - loss: 0.2728 - accuracy: 0.9700\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2717 - accuracy: 0.9700\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2706 - accuracy: 0.9800\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2700 - accuracy: 0.9800\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 633us/step - loss: 0.2686 - accuracy: 0.9800\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 932us/step - loss: 0.2680 - accuracy: 0.9800\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2675 - accuracy: 0.9700\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 495us/step - loss: 0.2673 - accuracy: 0.9700\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2677 - accuracy: 0.9700\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2667 - accuracy: 0.9700\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2648 - accuracy: 0.9700\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2639 - accuracy: 0.9800\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 517us/step - loss: 0.2625 - accuracy: 0.9800\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2617 - accuracy: 0.9800\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 539us/step - loss: 0.2611 - accuracy: 0.9800\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 757us/step - loss: 0.2609 - accuracy: 0.9900\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 725us/step - loss: 0.2594 - accuracy: 0.9800\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 410us/step - loss: 0.2584 - accuracy: 0.9800\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 672us/step - loss: 0.2576 - accuracy: 0.9800\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 718us/step - loss: 0.2571 - accuracy: 0.9900\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.9900\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 790us/step - loss: 0.2566 - accuracy: 0.9800\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 326us/step - loss: 0.2560 - accuracy: 0.9800\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 572us/step - loss: 0.2549 - accuracy: 0.9800\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 489us/step - loss: 0.2537 - accuracy: 0.9900\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 672us/step - loss: 0.2528 - accuracy: 0.9900\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 386us/step - loss: 0.2519 - accuracy: 0.9900\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 369us/step - loss: 0.2510 - accuracy: 0.9900\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2502 - accuracy: 0.9900\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 625us/step - loss: 0.2494 - accuracy: 0.9900\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2484 - accuracy: 0.9800\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2474 - accuracy: 0.9700\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.2467 - accuracy: 0.9700\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 295us/step - loss: 0.2469 - accuracy: 0.9700\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 251us/step - loss: 0.2478 - accuracy: 0.9700\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2482 - accuracy: 0.9700\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.9700\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2436 - accuracy: 0.9700\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.2426 - accuracy: 0.9800\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 894us/step - loss: 0.2417 - accuracy: 0.9800\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2405 - accuracy: 0.9700\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.2406 - accuracy: 0.9700\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 496us/step - loss: 0.2403 - accuracy: 0.9700\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 897us/step - loss: 0.2393 - accuracy: 0.9700\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2385 - accuracy: 0.9700\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2377 - accuracy: 0.9700\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.2374 - accuracy: 0.9700\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 625us/step - loss: 0.2364 - accuracy: 0.9700\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2357 - accuracy: 0.9700\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2350 - accuracy: 0.9700\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 849us/step - loss: 0.2344 - accuracy: 0.9800\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 568us/step - loss: 0.2345 - accuracy: 0.9800\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2335 - accuracy: 0.9900\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2326 - accuracy: 0.9800\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.2321 - accuracy: 0.9800\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2324 - accuracy: 0.9900\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2330 - accuracy: 0.9800\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 579us/step - loss: 0.2326 - accuracy: 0.9800\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 948us/step - loss: 0.2313 - accuracy: 0.9800\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.2296 - accuracy: 0.9900\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 746us/step - loss: 0.2287 - accuracy: 0.9900\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.2286 - accuracy: 0.9900\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2274 - accuracy: 0.9800\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 693us/step - loss: 0.2264 - accuracy: 0.9800\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2259 - accuracy: 0.9900\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 689us/step - loss: 0.2258 - accuracy: 0.9900\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 502us/step - loss: 0.2265 - accuracy: 0.9800\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 495us/step - loss: 0.2269 - accuracy: 0.9800\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.2266 - accuracy: 0.9800\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2258 - accuracy: 0.9800\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2243 - accuracy: 0.9800\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 780us/step - loss: 0.2220 - accuracy: 0.9900\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9700\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 787us/step - loss: 0.2208 - accuracy: 0.9700\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 663us/step - loss: 0.2206 - accuracy: 0.9700\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.2206 - accuracy: 0.9700\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2197 - accuracy: 0.9700\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2188 - accuracy: 0.9700\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2173 - accuracy: 0.9700\n",
      "Epoch 321/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 748us/step - loss: 0.2165 - accuracy: 0.9700\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 554us/step - loss: 0.2158 - accuracy: 0.9700\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 251us/step - loss: 0.2160 - accuracy: 0.9800\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 574us/step - loss: 0.2149 - accuracy: 0.9800\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.2144 - accuracy: 0.9700\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.2137 - accuracy: 0.9700\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 486us/step - loss: 0.2132 - accuracy: 0.9700\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2130 - accuracy: 0.9700\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 626us/step - loss: 0.2125 - accuracy: 0.9700\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2117 - accuracy: 0.9700\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 545us/step - loss: 0.2111 - accuracy: 0.9700\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 700us/step - loss: 0.2106 - accuracy: 0.9700\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 543us/step - loss: 0.2101 - accuracy: 0.9700\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 493us/step - loss: 0.2099 - accuracy: 0.9700\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.2098 - accuracy: 0.9700\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2095 - accuracy: 0.9700\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 718us/step - loss: 0.2083 - accuracy: 0.9700\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 354us/step - loss: 0.2076 - accuracy: 0.9700\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.2070 - accuracy: 0.9700\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.2070 - accuracy: 0.9700\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.2060 - accuracy: 0.9700\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2053 - accuracy: 0.9700\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2048 - accuracy: 0.9700\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.2046 - accuracy: 0.9800\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2050 - accuracy: 0.9900\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 512us/step - loss: 0.2049 - accuracy: 0.9900\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 434us/step - loss: 0.2052 - accuracy: 0.9800\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 406us/step - loss: 0.2042 - accuracy: 0.9900\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.2035 - accuracy: 0.9900\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 453us/step - loss: 0.2024 - accuracy: 0.9900\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 995us/step - loss: 0.2019 - accuracy: 0.9800\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 497us/step - loss: 0.2000 - accuracy: 0.9700\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1995 - accuracy: 0.9700\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 588us/step - loss: 0.1986 - accuracy: 0.9700\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2002 - accuracy: 0.9700\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2004 - accuracy: 0.9700\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2006 - accuracy: 0.9700\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 1.00 - 0s 749us/step - loss: 0.2002 - accuracy: 0.9700\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2003 - accuracy: 0.9700\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 765us/step - loss: 0.2004 - accuracy: 0.9700\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1992 - accuracy: 0.9700\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 418us/step - loss: 0.1978 - accuracy: 0.9700\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1967 - accuracy: 0.9700\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 246us/step - loss: 0.1963 - accuracy: 0.9700\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1962 - accuracy: 0.9700\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1963 - accuracy: 0.9700\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.1949 - accuracy: 0.9700\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 791us/step - loss: 0.1933 - accuracy: 0.9700\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1919 - accuracy: 0.9700\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.1916 - accuracy: 0.9700\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1914 - accuracy: 0.9700\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 313us/step - loss: 0.1909 - accuracy: 0.9700\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1903 - accuracy: 0.9700\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1898 - accuracy: 0.9700\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 678us/step - loss: 0.1895 - accuracy: 0.9700\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 0.1890 - accuracy: 0.9700\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1886 - accuracy: 0.9700\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1880 - accuracy: 0.9700\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 615us/step - loss: 0.1877 - accuracy: 0.9700\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1874 - accuracy: 0.9700\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1868 - accuracy: 0.9800\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1869 - accuracy: 0.9800\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1869 - accuracy: 0.9900\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 727us/step - loss: 0.1861 - accuracy: 0.9900\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 435us/step - loss: 0.1853 - accuracy: 0.9800\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 586us/step - loss: 0.1843 - accuracy: 0.9700\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 860us/step - loss: 0.1848 - accuracy: 0.9700\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1851 - accuracy: 0.9700\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1842 - accuracy: 0.9700\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 699us/step - loss: 0.1833 - accuracy: 0.9700\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 954us/step - loss: 0.1827 - accuracy: 0.9700\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1818 - accuracy: 0.9700\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1814 - accuracy: 0.9700\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1812 - accuracy: 0.9700\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1806 - accuracy: 0.9700\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 407us/step - loss: 0.1802 - accuracy: 0.9700\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 529us/step - loss: 0.1799 - accuracy: 0.9700\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 181us/step - loss: 0.1795 - accuracy: 0.9700\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.1793 - accuracy: 0.9700\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1789 - accuracy: 0.9700\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 249us/step - loss: 0.1784 - accuracy: 0.9700\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1783 - accuracy: 0.9700\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1777 - accuracy: 0.9700\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1773 - accuracy: 0.9700\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 245us/step - loss: 0.1773 - accuracy: 0.9700\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1766 - accuracy: 0.9700\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1758 - accuracy: 0.9700\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.1756 - accuracy: 0.9700\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.1753 - accuracy: 0.9700\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 497us/step - loss: 0.1754 - accuracy: 0.9900\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1751 - accuracy: 0.9900\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 495us/step - loss: 0.1747 - accuracy: 0.9800\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1737 - accuracy: 0.9700\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1731 - accuracy: 0.9700\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 546us/step - loss: 0.1727 - accuracy: 0.9700\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.1723 - accuracy: 0.9700\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1718 - accuracy: 0.9700\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 506us/step - loss: 0.1718 - accuracy: 0.9700\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1715 - accuracy: 0.9700\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1711 - accuracy: 0.9700\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1705 - accuracy: 0.9700\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1702 - accuracy: 0.9700\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1698 - accuracy: 0.9700\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1693 - accuracy: 0.9700\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1690 - accuracy: 0.9700\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1686 - accuracy: 0.9700\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1687 - accuracy: 0.9700\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 497us/step - loss: 0.1680 - accuracy: 0.9700\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1676 - accuracy: 0.9700\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 585us/step - loss: 0.1671 - accuracy: 0.9700\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.1665 - accuracy: 0.9700\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.1668 - accuracy: 0.9700\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 248us/step - loss: 0.1674 - accuracy: 0.9900\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9900\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1668 - accuracy: 0.9900\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 662us/step - loss: 0.1647 - accuracy: 0.9700\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1646 - accuracy: 0.9700\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 620us/step - loss: 0.1653 - accuracy: 0.9700\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1658 - accuracy: 0.9700\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 248us/step - loss: 0.1655 - accuracy: 0.9700\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1640 - accuracy: 0.9700\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 663us/step - loss: 0.1632 - accuracy: 0.9700\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1628 - accuracy: 0.9700\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.1625 - accuracy: 0.9700\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1622 - accuracy: 0.9700\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 503us/step - loss: 0.1617 - accuracy: 0.9700\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1620 - accuracy: 0.9700\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1627 - accuracy: 0.9700\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1625 - accuracy: 0.9700\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.1617 - accuracy: 0.9700\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1610 - accuracy: 0.9700\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1604 - accuracy: 0.9700\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 248us/step - loss: 0.1593 - accuracy: 0.9700\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 512us/step - loss: 0.1596 - accuracy: 0.9700\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.1590 - accuracy: 0.9700\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1586 - accuracy: 0.9700\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1583 - accuracy: 0.9700\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1580 - accuracy: 0.9700\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.1576 - accuracy: 0.9700\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1576 - accuracy: 0.9700\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 530us/step - loss: 0.1571 - accuracy: 0.9700\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 876us/step - loss: 0.1567 - accuracy: 0.9700\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1564 - accuracy: 0.9700\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1563 - accuracy: 0.9700\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.1559 - accuracy: 0.9700\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 503us/step - loss: 0.1559 - accuracy: 0.9700\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.1554 - accuracy: 0.9700\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.1554 - accuracy: 0.9700\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1552 - accuracy: 0.9700\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1543 - accuracy: 0.9700\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1545 - accuracy: 0.9700\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1543 - accuracy: 0.9700\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 732us/step - loss: 0.1544 - accuracy: 0.9700\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1552 - accuracy: 0.9700\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 936us/step - loss: 0.1561 - accuracy: 0.9700\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 375us/step - loss: 0.1548 - accuracy: 0.9700\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1533 - accuracy: 0.9700\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 329us/step - loss: 0.1528 - accuracy: 0.9700\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1516 - accuracy: 0.9700\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1513 - accuracy: 0.9700\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1510 - accuracy: 0.9700\n",
      "Epoch 482/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 498us/step - loss: 0.1509 - accuracy: 0.9700\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1501 - accuracy: 0.9700\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 508us/step - loss: 0.1503 - accuracy: 0.9700\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1498 - accuracy: 0.9700\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1494 - accuracy: 0.9700\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1492 - accuracy: 0.9700\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 558us/step - loss: 0.1491 - accuracy: 0.9700\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1492 - accuracy: 0.9700\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1492 - accuracy: 0.9700\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 744us/step - loss: 0.1489 - accuracy: 0.9700\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 502us/step - loss: 0.1477 - accuracy: 0.9700\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1476 - accuracy: 0.9700\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1480 - accuracy: 0.9800\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1477 - accuracy: 0.9800\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1470 - accuracy: 0.9800\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1467 - accuracy: 0.9700\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1461 - accuracy: 0.9700\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1472 - accuracy: 0.9800\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.1472 - accuracy: 0.9900\n",
      "2/2 [==============================] - 0s 504us/step - loss: 0.1511 - accuracy: 0.9400\n",
      "Test Accuracy: 0.940\n",
      "Predicted: [[9.9609864e-01 3.8825257e-03 1.8782475e-05]] (class number: 0) class name: ['Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "# mlp for multiclass classification using the Sequential API\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # default is 'last'\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "# load the dataset\n",
    "path = './datasets/iris.data'\n",
    "df = read_csv(path)\n",
    "\n",
    "# split into input and output columns\n",
    "X, y = df.values[:, :-1], df.values[:, -1]\n",
    "\n",
    "# ensure all data are floating point values\n",
    "X = X.astype('float32')\n",
    "\n",
    "# encode strings to integer\n",
    "le= LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(y)\n",
    "\n",
    "# split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "# define model\n",
    "\n",
    "l_in = Input(shape=(n_features,))\n",
    "l_hidden1 = Dense(10,activation='relu', kernel_initializer='he_normal')(l_in)\n",
    "#l_hidden2 = Dense(8,activation='relu', kernel_initializer='he_normal')(l_hidden1)\n",
    "l_out = Dense(3, activation='softmax')(l_hidden1)\n",
    "model = Model(inputs=l_in, outputs=l_out)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=32, verbose=1)\n",
    "\n",
    "# evaluate the model\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test Accuracy: {acc:.3f}')\n",
    "\n",
    "# make a prediction\n",
    "row = [5.1,3.5,1.4,0.2]\n",
    "yhat = model.predict([row])\n",
    "\n",
    "print(f'Predicted: {yhat} (class number: {argmax(yhat)}) class name: {le.inverse_transform([argmax(yhat)])}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rough-canvas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "(100, 4) (50, 4) (100,) (50,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c3e60bdb80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.000\n",
      "Predicted: [[9.996908e-01 3.092914e-04 1.446793e-09]] (class number: 0) class name: ['Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "# mlp for multiclass classification using the Sequential API\n",
    "\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# load the dataset\n",
    "path = './datasets/iris.data'\n",
    "df = read_csv(path)\n",
    "\n",
    "# split into input and output columns\n",
    "X, y = df.values[:, :-1], df.values[:, -1]\n",
    "# ensure all data are floating point values\n",
    "X = X.astype('float32')\n",
    "\n",
    "# encode strings to integer\n",
    "le= LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(y)\n",
    "# split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "#model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=32, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {acc:.3f}')\n",
    "\n",
    "# make a prediction\n",
    "row = [5.1,3.5,1.4,0.2]\n",
    "yhat = model.predict([row])\n",
    "\n",
    "print(f'Predicted: {yhat} (class number: {argmax(yhat)}) class name: {le.inverse_transform([argmax(yhat)])}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-insulation",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Models\n",
    "\n",
    "**Convolutional Neural Networks**, or **CNN**s for short, are a type of network designed for <u>image input</u>.<br>\n",
    "\n",
    "They are comprised of models with `convolutional layers` that extract features (called feature maps) and `pooling layers` that distill features down to the next layer.<br>\n",
    "\n",
    "### Convolution Layer\n",
    "\n",
    "CNN are composed of **Convolutional layers**. A Convolutional layer is the layers that focus on neighbouring/local properties of an image rather than the complete input image.\n",
    "A n\\*n 2D matrix with some predefined values is called a kernel. The kernel moves step by step on the entire image. Each value is multiplied with the corresponding inplace value on image and summed to get the output value:\n",
    "\n",
    "<img src=\"nbimages/convolution.jpeg\" alt=\"Convolution Layer\" title=\"Convolution Layer\" width=400 height=300 />\n",
    "\n",
    "Note that the size of the input reduces after convolution layer because it can't process values at the edges. For a 3x3 kernel size convolution, a NxN image converts to N-1xN-1 size.<br>\n",
    "\n",
    "The **tf.keras.layers.Conv2D()** convolution layer takes the following argument:<br>\n",
    "\n",
    "- **filter**: number of different types of convolutions used ,(initially they are set to some predefined convolution and slowly trained to find better features in the image).\n",
    "- **kernel_size**: 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "- **activation**: activation function\n",
    "- **input_shape** Size of each input to the convolution.\n",
    "\n",
    "Ex: `tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1))`\n",
    "\n",
    "\n",
    "### Pooling Layer\n",
    "\n",
    "**Pooling layers** are used to reduce the dimension of the image. There are many types of pooling layers in CNN like **Max Pooling**, **Average Pooling**, **Global Pooling** etc. The most common is **Max Pooling**.<br>\n",
    "\n",
    "In max pooling the pixel with maximum value is the output on a pool size of n\\*n:\n",
    "\n",
    "<img src=\"nbimages/filter.png\" alt=\"Pooling Layer\" title=\"Pooling Layer\" width=400 height=300 />\n",
    "\n",
    "The **tf.keras.layers.MaxPooling2D()** convolution layer takes the following argument:<br>\n",
    "\n",
    "- **pool_size**: Dimension of pooling kernel\n",
    "\n",
    "Ex: `tf.keras.layers.MaxPooling2D(2, 2)`\n",
    "\n",
    "\n",
    "CNNs are most well-suited to image classification tasks, although they can be used on a wide array of tasks that take images as input.<br>\n",
    "\n",
    "A popular image classification task is the `MNIST handwritten digit classification`. It involves tens of thousands of handwritten digits that must be classified as a number between 0 and 9.<br>\n",
    "\n",
    "The `tf.keras` API provides a convenience function to download and load this dataset directly: **`mnist.load_data()`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "discrete-emerald",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data: (60000, 28, 28)\n",
      "Shape of the training target: (60000,)\n",
      "Shape of the test data: (10000, 28, 28)\n",
      "Shape of the test target: (10000,)\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dc4990d220>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable is 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAN80lEQVR4nO3df6hcdXrH8c+ncf3DrBpTMYasNhuRWBWbLRqLSl2RrD9QNOqWDVgsBrN/GHChhEr6xyolEuqP0qAsuYu6sWyzLqgYZVkVo6ZFCF5j1JjU1YrdjV6SSozG+KtJnv5xT+Su3vnOzcyZOZP7vF9wmZnzzJnzcLife87Md879OiIEYPL7k6YbANAfhB1IgrADSRB2IAnCDiRxRD83ZpuP/oEeiwiPt7yrI7vtS22/aftt27d281oAesudjrPbniLpd5IWSNou6SVJiyJia2EdjuxAj/XiyD5f0tsR8U5EfCnpV5Ku6uL1APRQN2GfJekPYx5vr5b9EdtLbA/bHu5iWwC61M0HdOOdKnzjND0ihiQNSZzGA03q5si+XdJJYx5/R9L73bUDoFe6CftLkk61/V3bR0r6kaR19bQFoG4dn8ZHxD7bSyU9JWmKpAci4o3aOgNQq46H3jraGO/ZgZ7ryZdqABw+CDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii4ymbcXiYMmVKsX7sscf2dPtLly5tWTvqqKOK686dO7dYv/nmm4v1u+66q2Vt0aJFxXU///zzYn3lypXF+u23316sN6GrsNt+V9IeSfsl7YuIs+toCkD96jiyXxQRH9TwOgB6iPfsQBLdhj0kPW37ZdtLxnuC7SW2h20Pd7ktAF3o9jT+/Ih43/YJkp6x/V8RsWHsEyJiSNKQJNmOLrcHoENdHdkj4v3qdqekxyTNr6MpAPXrOOy2p9o++uB9ST+QtKWuxgDUq5vT+BmSHrN98HX+PSJ+W0tXk8zJJ59crB955JHF+nnnnVesX3DBBS1r06ZNK6577bXXFutN2r59e7G+atWqYn3hwoUta3v27Cmu++qrrxbrL7zwQrE+iDoOe0S8I+kvauwFQA8x9AYkQdiBJAg7kARhB5Ig7EASjujfl9om6zfo5s2bV6yvX7++WO/1ZaaD6sCBA8X6jTfeWKx/8sknHW97ZGSkWP/www+L9TfffLPjbfdaRHi85RzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlrMH369GJ948aNxfqcOXPqbKdW7XrfvXt3sX7RRRe1rH355ZfFdbN+/6BbjLMDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJM2VyDXbt2FevLli0r1q+44opi/ZVXXinW2/1L5ZLNmzcX6wsWLCjW9+7dW6yfccYZLWu33HJLcV3UiyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTB9ewD4JhjjinW200vvHr16pa1xYsXF9e9/vrri/W1a9cW6xg8HV/PbvsB2zttbxmzbLrtZ2y/Vd0eV2ezAOo3kdP4X0i69GvLbpX0bEScKunZ6jGAAdY27BGxQdLXvw96laQ11f01kq6uty0Adev0u/EzImJEkiJixPYJrZ5oe4mkJR1uB0BNen4hTEQMSRqS+IAOaFKnQ287bM+UpOp2Z30tAeiFTsO+TtIN1f0bJD1eTzsAeqXtabzttZK+L+l429sl/VTSSkm/tr1Y0u8l/bCXTU52H3/8cVfrf/TRRx2ve9NNNxXrDz/8cLHebo51DI62YY+IRS1KF9fcC4Ae4uuyQBKEHUiCsANJEHYgCcIOJMElrpPA1KlTW9aeeOKJ4roXXnhhsX7ZZZcV608//XSxjv5jymYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9knulFNOKdY3bdpUrO/evbtYf+6554r14eHhlrX77ruvuG4/fzcnE8bZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmTW7hwYbH+4IMPFutHH310x9tevnx5sf7QQw8V6yMjIx1vezJjnB1IjrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcHUVnnnlmsX7PPfcU6xdf3Plkv6tXry7WV6xYUay/9957HW/7cNbxOLvtB2zvtL1lzLLbbL9ne3P1c3mdzQKo30RO438h6dJxlv9LRMyrfn5Tb1sA6tY27BGxQdKuPvQCoIe6+YBuqe3XqtP841o9yfYS28O2W/8zMgA912nYfybpFEnzJI1IurvVEyNiKCLOjoizO9wWgBp0FPaI2BER+yPigKSfS5pfb1sA6tZR2G3PHPNwoaQtrZ4LYDC0HWe3vVbS9yUdL2mHpJ9Wj+dJCknvSvpxRLS9uJhx9sln2rRpxfqVV17ZstbuWnl73OHir6xfv75YX7BgQbE+WbUaZz9iAisuGmfx/V13BKCv+LoskARhB5Ig7EAShB1IgrADSXCJKxrzxRdfFOtHHFEeLNq3b1+xfskll7SsPf/888V1D2f8K2kgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSKLtVW/I7ayzzirWr7vuumL9nHPOaVlrN47eztatW4v1DRs2dPX6kw1HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2SW7u3LnF+tKlS4v1a665plg/8cQTD7mnidq/f3+xPjJS/u/lBw4cqLOdwx5HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2w0C7sexFi8abaHdUu3H02bNnd9JSLYaHh4v1FStWFOvr1q2rs51Jr+2R3fZJtp+zvc32G7ZvqZZPt/2M7beq2+N63y6ATk3kNH6fpL+PiD+X9FeSbrZ9uqRbJT0bEadKerZ6DGBAtQ17RIxExKbq/h5J2yTNknSVpDXV09ZIurpHPQKowSG9Z7c9W9L3JG2UNCMiRqTRPwi2T2ixzhJJS7rsE0CXJhx229+W9Iikn0TEx/a4c8d9Q0QMSRqqXoOJHYGGTGjozfa3NBr0X0bEo9XiHbZnVvWZknb2pkUAdWh7ZPfoIfx+Sdsi4p4xpXWSbpC0srp9vCcdTgIzZswo1k8//fRi/d577y3WTzvttEPuqS4bN24s1u+8886WtccfL//KcIlqvSZyGn++pL+V9LrtzdWy5RoN+a9tL5b0e0k/7EmHAGrRNuwR8Z+SWr1Bv7jedgD0Cl+XBZIg7EAShB1IgrADSRB2IAkucZ2g6dOnt6ytXr26uO68efOK9Tlz5nTSUi1efPHFYv3uu+8u1p966qli/bPPPjvkntAbHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIk04+znnntusb5s2bJiff78+S1rs2bN6qinunz66acta6tWrSque8cddxTre/fu7agnDB6O7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRJpx9oULF3ZV78bWrVuL9SeffLJY37dvX7FeuuZ89+7dxXWRB0d2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUjCEVF+gn2SpIcknSjpgKShiPhX27dJuknS/1ZPXR4Rv2nzWuWNAehaRIw76/JEwj5T0syI2GT7aEkvS7pa0t9I+iQi7ppoE4Qd6L1WYZ/I/Owjkkaq+3tsb5PU7L9mAXDIDuk9u+3Zkr4naWO1aKnt12w/YPu4FusssT1se7i7VgF0o+1p/FdPtL8t6QVJKyLiUdszJH0gKST9k0ZP9W9s8xqcxgM91vF7dkmy/S1JT0p6KiLuGac+W9KTEXFmm9ch7ECPtQp729N425Z0v6RtY4NefXB30EJJW7ptEkDvTOTT+Ask/Yek1zU69CZJyyUtkjRPo6fx70r6cfVhXum1OLIDPdbVaXxdCDvQex2fxgOYHAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9HvK5g8k/c+Yx8dXywbRoPY2qH1J9NapOnv7s1aFvl7P/o2N28MRcXZjDRQMam+D2pdEb53qV2+cxgNJEHYgiabDPtTw9ksGtbdB7Uuit071pbdG37MD6J+mj+wA+oSwA0k0Enbbl9p+0/bbtm9toodWbL9r+3Xbm5uen66aQ2+n7S1jlk23/Yztt6rbcefYa6i322y/V+27zbYvb6i3k2w/Z3ub7Tds31Itb3TfFfrqy37r+3t221Mk/U7SAknbJb0kaVFEbO1rIy3YflfS2RHR+BcwbP+1pE8kPXRwai3b/yxpV0SsrP5QHhcR/zAgvd2mQ5zGu0e9tZpm/O/U4L6rc/rzTjRxZJ8v6e2IeCcivpT0K0lXNdDHwIuIDZJ2fW3xVZLWVPfXaPSXpe9a9DYQImIkIjZV9/dIOjjNeKP7rtBXXzQR9lmS/jDm8XYN1nzvIelp2y/bXtJ0M+OYcXCarer2hIb7+bq203j309emGR+YfdfJ9OfdaiLs401NM0jjf+dHxF9KukzSzdXpKibmZ5JO0egcgCOS7m6ymWqa8Uck/SQiPm6yl7HG6asv+62JsG+XdNKYx9+R9H4DfYwrIt6vbndKekyjbzsGyY6DM+hWtzsb7ucrEbEjIvZHxAFJP1eD+66aZvwRSb+MiEerxY3vu/H66td+ayLsL0k61fZ3bR8p6UeS1jXQxzfYnlp9cCLbUyX9QIM3FfU6STdU92+Q9HiDvfyRQZnGu9U042p43zU+/XlE9P1H0uUa/UT+vyX9YxM9tOhrjqRXq583mu5N0lqNntb9n0bPiBZL+lNJz0p6q7qdPkC9/ZtGp/Z+TaPBmtlQbxdo9K3ha5I2Vz+XN73vCn31Zb/xdVkgCb5BByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/D+f1mbt6t55/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# The dataset contains images, each image of 28x28 px. \n",
    "# There are 60.000 images in training data and 10.000 images in test data.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Overview of the dataset\n",
    "\n",
    "print(f'Shape of the training data: {x_train.shape}')\n",
    "print(f'Shape of the training target: {y_train.shape}')\n",
    "print(f'Shape of the test data: {x_test.shape}')\n",
    "print(f'Shape of the test target: {y_test.shape}')\n",
    "\n",
    "print(y_train)\n",
    "\n",
    "# Let's plot the first image in the training data and look at it's \n",
    "# corresponding target (y) variable.\n",
    "plt.imshow(x_train[0], cmap='gray')\n",
    "print(f'Target variable is {y_train[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-insertion",
   "metadata": {},
   "source": [
    "In the following lines of code we reshape the data to feed in the Model. <br>\n",
    "You can see the data reshaped to (60000, 28, 28, 1):\n",
    "- 60000 is the number of images, \n",
    "- 28, 28 is the shape of image \n",
    "- 1 is the number of channels in the image: grayscale images have 1 channel, colored images have 3 channels\n",
    "\n",
    "The next step is **Normalizing** i.e. scaling the pixels to 0-1 from 0-255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "outdoor-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the data\n",
    "\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "# Normalizing\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-newark",
   "metadata": {},
   "source": [
    "Let's look at details of the model:\n",
    "\n",
    "- The 3x3 pixel kernel reduces the image size by 1 pixel on every size because it can't process the pixels at the edges and the 64 types of filter outputs 64 layers of matrix converting to a output of (26, 26, 64).<br>\n",
    "- The Max Pooling of pool size 2x2 reduces the image by half (output shape is (13, 13, 64)).<br>\n",
    "- The next layers are again a convolution and max pooling with the net output of shape (5, 5, 64).<br>\n",
    "- The flatten layer unrolls the input to a single dimension array i.e. 5 x 5 x 64 = 1600. <br>\n",
    "- The number of nodes in the next layer is fixed by us to 128. <br>\n",
    "- Final output layer contains 10 nodes for 10 classes.<br>\n",
    "\n",
    "The **model.summary()** method will return quick overview of the components of your Keras model. <br>\n",
    "\n",
    "You can also create a plot of your model by calling the **plot_model()** function. This will create an image file that contains a box and line diagram of the layers in your model.<br>\n",
    "\n",
    "**Note**: the more trainable parameters your model has (a value you get from the summary), the more computing power you need, furthermore with to many trainable parameters, your model is more vulnerable to overfitting.\n",
    "\n",
    "**Note**: **tf.keras.layers.Flatten()** flattens the input.<br>\n",
    "For input of (batch_size, height, width) the output converts to (batch_size, height\\*width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "electronic-lithuania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-brake",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "The **model.fit()** method trains the model. It gets the following arguments:\n",
    "\n",
    "- **x_train**: Training data/features\n",
    "- **y_train**: Target\n",
    "- **epochs**: Number of times the entire dataset is fed in the model. The number of epochs are a kind of try and test metrics. It depends on a number of factors like size of data and complexity of classification, etc. You will slowly get a feeling of how to estimate number of epochs required for a particular model and dataset.\n",
    "\n",
    "While training you can see the **loss** and **accuracy** calculated on the training data itself. \n",
    "\n",
    "### Validating the model\n",
    "\n",
    "During the training phase, we do see the accuracy level. This accuracy is calculated on the same data on which the model is trained. <br>\n",
    "To validate the model we should check it's accuracy when it gets new data on which it is not trained.<br>\n",
    "The **model.evaluate()** method is used for this test.<br>\n",
    "If the model gives high accuracy on training data but low accuracy on test data it is **overfitting**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "equivalent-success",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.1254 - accuracy: 0.9618\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0416 - accuracy: 0.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc467d0dc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0374 - accuracy: 0.9875\n",
      "Validation loss: 0.0374450646340847\n",
      "Validation accuracy: 0.987500011920929\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(x_train, y_train, epochs=2)\n",
    "\n",
    "# Validation\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Validation loss: {val_loss}')\n",
    "print(f'Validation accuracy: {val_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-enzyme",
   "metadata": {},
   "source": [
    "## How to Save and Load Your Model\n",
    "\n",
    "After having trained and evaluated a model we may want to re-use it later without retraining it each time.<br>\n",
    "\n",
    "This can be achieved by saving the model to file and later loading it and using it to make predictions.<br>\n",
    "\n",
    "This can be achieved using the **save()** method on the model to save the model.<br>\n",
    "\n",
    "`model.save('CNNMinistModel.h5')`\n",
    "\n",
    "It can be loaded later using the **load_model()** function.<br>\n",
    "\n",
    "`from tensorflow.keras.models import load_model\n",
    "model = load_model('CNNMinistModel.h5')`\n",
    "\n",
    "<br>\n",
    "The model is saved in **H5 format**, an efficient array storage format. As such, you must ensure that the `h5py` library is installed :\n",
    "\n",
    "`pip install h5py`\n",
    "\n",
    "or\n",
    "\n",
    "`conda install h5py`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-flesh",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "Neural networks are challenging to train: too little training and the model underfits; too much training and the model overfits the training dataset.<br>Both cases result in a model that is less effective than it could be.\n",
    "\n",
    "<br>\n",
    "One approach to solving this problem is to use **early stopping**. This involves monitoring the loss on the training dataset and a validation dataset. As soon as loss for the validation set starts to show signs of overfitting, the training process can be stopped.<br>\n",
    "\n",
    "To use **early stopping**, first you need a validation dataset. You can define the validation dataset manually via the **validation_data** argument to the `fit()` method, or you can use the **validation_split** argument and specify the amount of the training dataset to hold back for validation.<br>\n",
    "\n",
    "You can then define an **EarlyStopping** instance and instruct it on which performance measure to monitor, such as **val_loss** for loss on the validation dataset.<br>\n",
    "Training will stop when the chosen performance measure stops improving. To discover the training epoch on which training was stopped, the **verbose** argument can be set to 1. <br>\n",
    "\n",
    "Often, the first sign of no further improvement may not be the best time to stop training. This is because the model may coast into a plateau of no improvement or even get slightly worse before getting much better.<br>\n",
    "\n",
    "We can account for this by adding a delay to the trigger in terms of the number of epochs on which we would like to see no improvement. This can be done by setting the **patience** argument.<br>\n",
    "\n",
    "This `EarlyStopping` object can then be provided to the `fit()` method via the **callbacks** argument.<br>\n",
    "This allows you to set the number of epochs to a large number and be confident that training will end as soon as the model starts overfitting.<br> \n",
    "\n",
    "The `EarlyStopping` callback will stop training once triggered, but the model at the end of training may not be the model with best performance on the validation dataset.<br>\n",
    "\n",
    "An additional callback is required that will save the best model observed during training for later use. This is the **ModelCheckpoint** callback.<br>\n",
    "\n",
    "The **ModelCheckpoint** can be used to save the best model observed during training as defined by a chosen performance measure on the validation dataset.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adjusted-equality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1313/1313 [==============================] - 95s 72ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.0381 - val_accuracy: 0.9893\n",
      "Epoch 2/10\n",
      "1313/1313 [==============================] - 93s 71ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.0374 - val_accuracy: 0.9902\n",
      "Epoch 3/10\n",
      "  58/1313 [>.............................] - ETA: 1:20 - loss: 0.0109 - accuracy: 0.9973"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-84f929a34f04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', verbose=1)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss')\n",
    "\n",
    "# Training\n",
    "model.fit(x_train, y_train, epochs=500, validation_split=0.3, callbacks=[es, mc])\n",
    "\n",
    "# Validation\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-lloyd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
